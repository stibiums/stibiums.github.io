<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 人工智能中的编程 - 第5章: 并行算法II（Parallel Algorithms II） | STIBIUMS_WEB </title> <meta name="author" content="stibiums liu"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/touxiang.jpg?68b4199d95528c9129ff55a104244865"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://stibiums.github.io/notes/AIP-ch05/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> STIBIUMS_WEB </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">人工智能中的编程 - 第5章: 并行算法II（Parallel Algorithms II）</h1> <p class="post-meta"> Created on September 24, 2025 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2025   ·   <i class="fa-solid fa-hashtag fa-sm"></i> notes   <i class="fa-solid fa-hashtag fa-sm"></i> AIP   ·   <i class="fa-solid fa-tag fa-sm"></i> AIP </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="并行排序算法">并行排序算法</h2> <p>排序是计算机科学中的基础问题，正如Donald Knuth在《计算机程序设计艺术》第3卷中用722页来详述排序和搜索算法。在GPU并行计算中，排序算法的设计面临着独特的挑战和机遇。</p> <h2 id="砖块排序brick-sort">砖块排序（Brick Sort）</h2> <h3 id="基本思想">基本思想</h3> <p>砖块排序本质上是冒泡排序的并行化版本：</p> <p><strong>复杂度分析</strong>：</p> <ul> <li>工作复杂度：$O(N^2)$</li> <li>步复杂度：$O(N)$</li> </ul> <h3 id="算法执行过程">算法执行过程</h3> <p>砖块排序通过交替执行两种比较模式：</p> <ol> <li> <strong>奇偶比较阶段</strong>：比较相邻的奇偶位置对</li> <li> <strong>偶奇比较阶段</strong>：比较相邻的偶奇位置对</li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/notes_img/AIP-ch05/brick_sort_process-480.webp 480w,/assets/img/notes_img/AIP-ch05/brick_sort_process-800.webp 800w,/assets/img/notes_img/AIP-ch05/brick_sort_process-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/notes_img/AIP-ch05/brick_sort_process.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><strong>正确性问题</strong>：虽然并行化提高了效率，但需要仔细验证算法的正确性。</p> <h2 id="归并排序merge-sort">归并排序（Merge Sort）</h2> <h3 id="分治思想">分治思想</h3> <p>归并排序基于分治范式，关键在于如何合并两个已排序的数组：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">merge_sort</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">arr</span><span class="p">,</span> <span class="kt">int</span> <span class="n">left</span><span class="p">,</span> <span class="kt">int</span> <span class="n">right</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">left</span> <span class="o">&lt;</span> <span class="n">right</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">mid</span> <span class="o">=</span> <span class="kt">int</span><span class="p">((</span><span class="n">left</span> <span class="o">+</span> <span class="n">right</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">);</span>
        <span class="n">merge_sort</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">left</span><span class="p">,</span> <span class="n">mid</span><span class="p">);</span>
        <span class="n">merge_sort</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">mid</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">right</span><span class="p">);</span>
        <span class="n">merge</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">left</span><span class="p">,</span> <span class="n">mid</span><span class="p">,</span> <span class="n">right</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p><strong>复杂度</strong>：$O(N \log N)$，递推关系为 $T_N = 2T_{N/2} + N$</p> <h3 id="gpu上的归并排序">GPU上的归并排序</h3> <p>由于CUDA不支持递归kernel，需要采用自底向上的方式：</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/notes_img/AIP-ch05/merge_sort_gpu-480.webp 480w,/assets/img/notes_img/AIP-ch05/merge_sort_gpu-800.webp 800w,/assets/img/notes_img/AIP-ch05/merge_sort_gpu-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/notes_img/AIP-ch05/merge_sort_gpu.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><strong>三种策略</strong>：</p> <ol> <li> <strong>许多小并行子问题</strong>：每个线程负责一次合并</li> <li> <strong>少数中等并行子问题</strong>：每个块负责一次合并，利用共享内存和二分搜索</li> <li> <strong>少数大并行子问题</strong>：跨块合并，使用Merge Path算法</li> </ol> <h3 id="合并操作优化">合并操作优化</h3> <p><strong>中等子问题的处理</strong>：</p> <ul> <li>利用共享内存提高访问速度</li> <li>使用二分搜索优化合并过程</li> </ul> <p><strong>大子问题的处理</strong>：</p> <ul> <li>采用Merge Path算法将大问题分解为小问题</li> <li>参考文献：”Merge Path - Parallel Merging Made Simple” (IEEE IPDPS 2012)</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/notes_img/AIP-ch05/knuth_sorting-480.webp 480w,/assets/img/notes_img/AIP-ch05/knuth_sorting-800.webp 800w,/assets/img/notes_img/AIP-ch05/knuth_sorting-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/notes_img/AIP-ch05/knuth_sorting.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="排序网络sorting-networks">排序网络（Sorting Networks）</h2> <h3 id="基本概念">基本概念</h3> <p>排序网络由一组比较器和连接线组成：</p> <p><strong>比较器</strong>：</p> <ul> <li>输入：x和y</li> <li>输出：x’ = min(x,y), y’ = max(x,y)</li> </ul> <h3 id="网络深度">网络深度</h3> <p>排序网络的运行时间与其深度成正比：</p> <p><strong>深度计算规则</strong>：</p> <ul> <li>输入线的深度为0</li> <li>比较器的输出深度 = max(输入深度) + 1</li> </ul> <h3 id="经典排序算法的网络表示">经典排序算法的网络表示</h3> <p><strong>冒泡排序网络</strong>：</p> <ul> <li>步复杂度：$O(N)$</li> </ul> <p><strong>插入排序网络</strong>：</p> <ul> <li>步复杂度：$O(N)$</li> </ul> <h3 id="双调排序网络bitonic-sorting-network">双调排序网络（Bitonic Sorting Network）</h3> <p><strong>双调序列定义</strong>：</p> <ul> <li>单调递增然后单调递减的序列</li> <li>或者可以循环移位成为这样的序列</li> </ul> <p><strong>示例</strong>：</p> <ul> <li>[1, 4, 6, 8, 3, 2]</li> <li>[6, 9, 4, 2, 3, 5]</li> <li>[0, 0, 1, 1, 0, 0]</li> </ul> <h3 id="zero-one原理">Zero-One原理</h3> <p><strong>引理</strong>：如果一个比较网络能正确转换输入序列a到输出序列b，那么对于任何单调递增函数f，该网络也能正确转换f(a)到f(b)。</p> <p>这意味着只需验证网络在0-1序列上的正确性。</p> <h3 id="半清理器half-cleaner">半清理器（Half-Cleaner）</h3> <p><strong>性质</strong>：如果输入是0和1的双调序列，则输出满足：</p> <ul> <li>上半部分和下半部分都是双调的</li> <li>至少一半是”干净的”（全0或全1）</li> </ul> <h3 id="双调排序器复杂度">双调排序器复杂度</h3> <p><strong>递推关系</strong>：</p> \[T(n) = \begin{cases} 0 &amp; \text{if } n = 1 \\ T(n/2) + 1 &amp; \text{if } n = 2^k \text{ and } k \geq 1 \end{cases}\] <p><strong>结果</strong>：$T(n) = O(\log n)$</p> <h3 id="归并网络">归并网络</h3> <p>将两个已排序数组合并为双调序列的技巧：</p> <ul> <li>反转第二个序列的顺序</li> <li>连接两个序列得到双调序列</li> </ul> <h3 id="完整排序网络">完整排序网络</h3> <p><strong>SORTER[n]递推</strong>：</p> \[T(n) = \begin{cases} 0 &amp; \text{if } n = 1 \\ T(n/2) + \log n &amp; \text{if } n = 2^k \text{ and } k \geq 1 \end{cases}\] <p><strong>总复杂度</strong>：$T(n) = O(\log^2 n)$</p> <h2 id="排序网络历史">排序网络历史</h2> <ul> <li> <strong>1954年</strong>：P.N. Armstrong, R.J.Nelson和D.J.O’Connor首次探索排序网络</li> <li> <strong>1960年代早期</strong>：K.E. Batcher发现第一个能在$O(\log n)$时间内合并两个n元素序列的网络</li> <li> <strong>1983年</strong>：AKS排序网络，能在深度$O(\log n)$内使用$O(n \log n)$个比较器排序n个数</li> </ul> <h2 id="基数排序radix-sort">基数排序（Radix Sort）</h2> <h3 id="基本思想-1">基本思想</h3> <p>基数排序是按位数字排序：</p> <p><strong>错误做法</strong>：从最高有效位开始排序 <strong>正确做法</strong>：从最低有效位开始，使用辅助的稳定排序</p> <h3 id="并行优化">并行优化</h3> <p><strong>关键观察</strong>：可以使用之前介绍的紧缩（Compact）算法来排序二进制位。</p> <p><strong>复杂度</strong>：每位的排序复杂度为$O(\log N)$</p> <h2 id="cuda流streams">CUDA流（Streams）</h2> <h3 id="默认流stream-0">默认流（Stream ‘0’）</h3> <p><strong>特点</strong>：</p> <ul> <li>未指定流时使用Stream 0</li> <li>默认流中的所有CUDA操作都是同步的</li> <li>GPU kernel默认与主机异步执行</li> </ul> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// 完全同步执行</span>
<span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev1</span><span class="p">,</span> <span class="n">host1</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">H2D</span><span class="p">);</span>
<span class="n">kernel2</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span> <span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...,</span> <span class="n">dev2</span><span class="p">,</span> <span class="p">...);</span>
<span class="n">some_cpu_method</span><span class="p">();</span> <span class="c1">// 可能重叠</span>
<span class="n">kernel3</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span> <span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...,</span> <span class="n">dev3</span><span class="p">,</span> <span class="p">...);</span>
<span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">host4</span><span class="p">,</span> <span class="n">dev4</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">D2H</span><span class="p">);</span>
</code></pre></div></div> <h3 id="并发性concurrency">并发性（Concurrency）</h3> <p><strong>定义</strong>：同时执行多个CUDA操作的能力，超越多线程并行性。</p> <p><strong>支持的操作类型</strong>：</p> <ul> <li>CUDA Kernel执行</li> <li>cudaMemcpyAsync (Host到Device)</li> <li>cudaMemcpyAsync (Device到Host)</li> <li>CPU计算</li> </ul> <p><strong>Fermi GPU架构支持</strong>：</p> <ul> <li>最多16个并发CUDA kernel（实际中少于4个）</li> <li>2个cudaMemcpyAsync（必须是不同方向）</li> <li>CPU计算</li> </ul> <h3 id="性能提升示例">性能提升示例</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/notes_img/AIP-ch05/stream_performance-480.webp 480w,/assets/img/notes_img/AIP-ch05/stream_performance-800.webp 800w,/assets/img/notes_img/AIP-ch05/stream_performance-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/notes_img/AIP-ch05/stream_performance.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>通过重叠kernel执行和内存传输，可以获得1.33倍的性能提升。</p> <h3 id="流的异步使用">流的异步使用</h3> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cudaStream_t</span> <span class="n">stream1</span><span class="p">,</span> <span class="n">stream2</span><span class="p">,</span> <span class="n">stream3</span><span class="p">,</span> <span class="n">stream4</span><span class="p">;</span>
<span class="n">cudaStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stream1</span><span class="p">);</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dev1</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
<span class="n">cudaMallocHost</span><span class="p">(</span><span class="o">&amp;</span><span class="n">host1</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span> <span class="c1">// 主机端需要固定内存</span>

<span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">dev1</span><span class="p">,</span> <span class="n">host1</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">H2D</span><span class="p">,</span> <span class="n">stream1</span><span class="p">);</span>
<span class="n">kernel2</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">stream2</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...,</span> <span class="n">dev2</span><span class="p">,</span> <span class="p">...);</span>
<span class="n">kernel3</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">stream3</span><span class="o">&gt;&gt;&gt;</span><span class="p">(...,</span> <span class="n">dev3</span><span class="p">,</span> <span class="p">...);</span>
<span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">host4</span><span class="p">,</span> <span class="n">dev4</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">D2H</span><span class="p">,</span> <span class="n">stream4</span><span class="p">);</span>
<span class="n">some_CPU_method</span><span class="p">();</span>
</code></pre></div></div> <p><strong>重要要求</strong>：</p> <ul> <li>完全异步/并发执行</li> <li>并发操作使用的数据必须是独立的</li> </ul> <h3 id="固定内存pinned-memory">固定内存（Pinned Memory）</h3> <p><strong>优势</strong>：从固定（页锁定）内存的主机到GPU复制速度更快</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cudaMallocHost</span><span class="p">(</span><span class="o">&amp;</span><span class="n">host1</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span> <span class="c1">// 固定内存</span>
</code></pre></div></div> <p><strong>PyTorch中的应用</strong>：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># DataLoader中的pin_memory参数
</span><span class="nc">DataLoader</span><span class="p">(...,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <h3 id="显式同步">显式同步</h3> <p><strong>同步所有操作</strong>：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cudaDeviceSynchronize</span><span class="p">()</span> <span class="c1">// 阻塞主机直到所有CUDA调用完成</span>
</code></pre></div></div> <p><strong>同步特定流</strong>：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">streamid</span><span class="p">)</span> <span class="c1">// 阻塞直到指定流完成</span>
</code></pre></div></div> <p><strong>使用事件同步</strong>：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">streamid</span><span class="p">)</span>
<span class="n">cudaEventSynchronize</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>
<span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="n">event</span><span class="p">)</span>
<span class="n">cudaEventQuery</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>
</code></pre></div></div> <h2 id="总结">总结</h2> <h3 id="核心排序算法回顾">核心排序算法回顾</h3> <ol> <li> <strong>砖块排序</strong>：简单并行化，但效率不高</li> <li> <strong>归并排序</strong>：分治思想，在GPU上需要自底向上实现</li> <li> <strong>排序网络</strong>：固定比较序列，深度决定性能</li> <li> <strong>基数排序</strong>：利用并行紧缩算法优化位排序</li> </ol> <h3 id="性能优化原则">性能优化原则</h3> <ol> <li> <strong>并行度选择</strong>：最大并行度不一定是最优选择</li> <li> <strong>内存访问模式</strong>：合并访问比分散访问更重要</li> <li> <strong>流的使用</strong>：通过异步操作重叠计算和通信</li> <li> <strong>算法复杂度权衡</strong>：在步复杂度和工作复杂度间平衡</li> </ol> <h3 id="cuda流的核心价值">CUDA流的核心价值</h3> <p>CUDA流技术使得GPU计算能够真正实现：</p> <ul> <li> <strong>计算与通信重叠</strong>：在执行kernel的同时进行内存传输</li> <li> <strong>多任务并发</strong>：同时处理多个独立的计算任务</li> <li> <strong>资源利用率最大化</strong>：充分利用GPU的并行执行单元</li> </ul> <p>这些技术为构建高性能GPU应用程序提供了重要基础，特别是在深度学习等需要处理大规模数据的场景中。</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesof_ML/">notes of ML</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesofvci/">notes of VCI</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesofaip/">notes of AIP</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesof_aimath/">notes of AI Math Fundamentals</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesof_ICS/">notes of ICS</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 stibiums liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: October 25, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?58fdb075e5aa03fbb8617845abde746c"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>