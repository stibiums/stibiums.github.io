<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 人工智能中的编程 - 第3章: 并行通信（Parallel Communication） | STIBIUMS_WEB </title> <meta name="author" content="stibiums liu"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/touxiang.jpg?68b4199d95528c9129ff55a104244865"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://stibiums.github.io/notes/AIP-ch03/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> STIBIUMS_WEB </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">人工智能中的编程 - 第3章: 并行通信（Parallel Communication）</h1> <p class="post-meta"> Created on September 18, 2025 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2025   ·   <i class="fa-solid fa-hashtag fa-sm"></i> notes   <i class="fa-solid fa-hashtag fa-sm"></i> AIP   ·   <i class="fa-solid fa-tag fa-sm"></i> AIP </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="上节课回顾">上节课回顾</h2> <ul> <li> <strong>并行编程的必要性</strong>：时钟频率无法无限提升</li> <li> <strong>第一个CUDA程序</strong>：实现ReLU激活函数</li> <li> <strong>GPU内存模型</strong>：Local/Shared/Global内存层次结构</li> <li> <strong>线程组织</strong>：Thread/Block/Grid三级架构</li> </ul> <h2 id="线程块与编程人员">线程块与编程人员</h2> <p>kernels: C/C++ functions (<code class="language-plaintext highlighter-rouge">__global__</code>)</p> <p><strong>线程块 (Thread Blocks)</strong>：协作解决子问题的线程组</p> <ul> <li>程序员负责定义块结构</li> <li>GPU负责将线程块分配给硬件SM</li> </ul> <h3 id="线程块与gpu硬件">线程块与GPU硬件</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>thread → GPU core
thread block → Streaming Multiprocessor (SM)
</code></pre></div></div> <p><strong>关键特性</strong>：</p> <ul> <li>一个线程块必须在一个SM上运行；一个SM可以运行多个块</li> <li>程序员负责定义块；GPU负责分配线程块到硬件SM</li> <li>线程并行运行，CUDA对线程块何时何地运行提供很少保证</li> <li>效率、简洁性、可扩展性</li> <li>块之间无通信（避免死锁）</li> </ul> <h2 id="cuda执行保证与限制">CUDA执行保证与限制</h2> <h3 id="线程块执行特点">线程块执行特点</h3> <p><strong>CUDA的少量保证</strong>：</p> <ul> <li>对线程块何时何地执行提供很少保证</li> <li>不同块/线程并行运行</li> <li>块之间不能通信（避免死锁）</li> </ul> <p><strong>确定性保证</strong>：</p> <ul> <li>块内所有线程在同一SM上同时运行</li> <li>当前kernel的所有块完成后，下一个kernel的块才开始</li> </ul> <h3 id="线程块编程示例">线程块编程示例</h3> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">hello</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Hello world! I'm a thread in block %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">hello</span><span class="o">&lt;&lt;&lt;</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"That's all!</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>不同运行的结果会改变吗？这个程序在不同运行中可以产生多少种不同的结果？</p> <p>答案：<strong>16!</strong> 种结果（让我们试试看）</p> <p>没有 <code class="language-plaintext highlighter-rouge">cudaDeviceSynchronize()</code> 会发生什么？</p> <h3 id="另一个线程块编程示例">另一个线程块编程示例</h3> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">hello</span><span class="p">(</span><span class="kt">float</span> <span class="n">f</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Hello world! I'm thread %d, f=%f</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">hello</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="mi">1</span><span class="p">.</span><span class="mi">2345</span><span class="n">f</span><span class="p">);</span>
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"That's all!</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>输出示例：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Hello thread 2, f=1.2345
Hello thread 1, f=1.2345
Hello thread 4, f=1.2345
Hello thread 0, f=1.2345
Hello thread 3, f=1.2345
</code></pre></div></div> <p><strong>注意</strong>：在kernel中使用printf非常耗时</p> <h2 id="simt单指令多线程-single-instruction-multiple-thread">SIMT：单指令多线程 (Single-Instruction, Multiple-Thread)</h2> <p>GPU多处理器以<strong>32个并行线程</strong>为组（称为<strong>warp</strong>）来创建、管理、调度和执行线程。</p> <ul> <li> <strong>Warp执行</strong>：一个warp同时执行一条共同指令，当所有32个线程在执行路径上一致时实现完全效率</li> <li> <strong>分支分化</strong>：如果warp内线程通过数据相关的条件分支发生分化，warp会执行每个分支路径，禁用不在该路径上的线程</li> <li> <strong>分化范围</strong>：分支分化只在warp内发生；不同warp独立执行，无论它们执行相同还是不同的代码路径</li> </ul> <h3 id="分支分化-thread-divergence">分支分化 (Thread Divergence)</h3> <p>当warp内线程执行不同的条件分支时发生分化：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="p">(</span><span class="n">condition</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 一些代码行</span>
<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="c1">// 其他代码行</span>
<span class="p">}</span>
</code></pre></div></div> <p><strong>分化处理机制</strong>：</p> <ul> <li>Warp串行执行每个分支路径</li> <li>禁用不在当前路径的线程（等待状态）</li> <li>分化只影响warp内部，不同warp独立执行</li> </ul> <h3 id="分支分化示例">分支分化示例</h3> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 一些代码行</span>
<span class="p">}</span>
</code></pre></div></div> <p>不同线程执行不同次数的循环，造成warp内分化，降低执行效率。</p> <h2 id="线程同步-thread-synchronization">线程同步 (Thread Synchronization)</h2> <h3 id="并行线程如何协作">并行线程如何协作？</h3> <p>线程可以通过<strong>全局内存和共享内存</strong>访问彼此的结果</p> <p><strong>注意事项</strong>：</p> <ul> <li>一个线程在另一个线程写入前读取结果</li> <li>多个线程写入同一内存位置（例如求和）</li> </ul> <p><strong>线程需要同步来协作</strong></p> <p><strong>屏障 (Barrier)</strong>：程序中线程停止并等待所有线程到达屏障的点；然后线程继续执行。</p> <h3 id="使用屏障避免数据竞争">使用屏障避免数据竞争</h3> <p>错误的代码：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="kt">int</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">128</span><span class="p">;</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">shift_sum</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">array</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">idx</span> <span class="o">&lt;</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">array</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">array</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">array</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span>  <span class="c1">// !!! 可能的BUG</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>正确的代码：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">shift_sum</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">array</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">idx</span> <span class="o">&lt;</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">float</span> <span class="n">tmp</span> <span class="o">=</span> <span class="n">array</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">array</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span>
        <span class="n">__syncthreads</span><span class="p">();</span>
        <span class="n">array</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <h3 id="使用屏障避免数据竞争--共享内存">使用屏障避免数据竞争 + 共享内存</h3> <p>使用共享内存减少全局内存访问：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">shift_sum</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">array</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 共享内存可以被块内所有线程访问</span>
    <span class="n">__shared__</span> <span class="kt">float</span> <span class="n">shared</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>

    <span class="c1">// 填充共享内存</span>
    <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="n">shared</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">array</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
    <span class="n">__syncthreads</span><span class="p">();</span>

    <span class="c1">// 执行"移位求和"</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">idx</span> <span class="o">&lt;</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">array</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">shared</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">shared</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span>
    <span class="p">}</span>

    <span class="c1">// 以下代码无效果</span>
    <span class="n">shared</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span><span class="p">.</span><span class="mi">14</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <h3 id="线程协作的另一个示例">线程协作的另一个示例</h3> <p>大量线程读写相同内存位置</p> <ul> <li>例如，100万个线程增量10个数组元素</li> </ul> <p>错误的方法：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="kt">int</span> <span class="n">kNumThreads</span> <span class="o">=</span> <span class="mi">1000000</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">int</span> <span class="n">kArraySize</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">int</span> <span class="n">kBlockWidth</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">;</span>

<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">increment_naive</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 线程索引</span>
    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// 每个线程增量连续元素</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="n">kArraySize</span><span class="p">;</span>
    <span class="n">g</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">g</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">increment_naive</span><span class="o">&lt;&lt;&lt;</span><span class="n">kNumThreads</span><span class="o">/</span><span class="n">kBlockWidth</span><span class="p">,</span> <span class="n">kBlockWidth</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_array</span><span class="p">);</span>
</code></pre></div></div> <p>这个程序能产生正确结果吗？ <code class="language-plaintext highlighter-rouge">__syncthreads()</code> 能修复这个bug吗？</p> <h3 id="原子内存操作">原子内存操作</h3> <p><strong>原子内存操作</strong>：在内存位置上以线程安全方式执行读-修改-写操作。</p> <p>这些操作提供了确保在给定时间只有一个线程可以读或写内存位置的方法。</p> <p>常用操作包括 <code class="language-plaintext highlighter-rouge">atomicAdd</code>、<code class="language-plaintext highlighter-rouge">atomicMin</code>、<code class="language-plaintext highlighter-rouge">atomicCAS</code></p> <p><strong>atomicCAS</strong>: 比较并交换</p> <ul> <li>我们可以使用 <code class="language-plaintext highlighter-rouge">atomicCAS</code> 构造通用原子操作</li> </ul> <p>正确的方法：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">increment_atomic</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 线程索引</span>
    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// 每个线程增量连续元素</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="n">kArraySize</span><span class="p">;</span>
    <span class="n">atomicAdd</span><span class="p">(</span><span class="o">&amp;</span><span class="n">g</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">1</span><span class="p">);</span>
<span class="p">}</span>

<span class="n">increment_atomic</span><span class="o">&lt;&lt;&lt;</span><span class="n">kNumThreads</span><span class="o">/</span><span class="n">kBlockWidth</span><span class="p">,</span> <span class="n">kBlockWidth</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_array</span><span class="p">);</span>
</code></pre></div></div> <p>我们必须使用 <code class="language-plaintext highlighter-rouge">atomicAdd()</code>。让我们运行代码试试看！</p> <h3 id="原子操作的局限性">原子操作的局限性</h3> <p><strong>结果不完全可重现</strong></p> <ul> <li>例如，$s = \sum_{i=1}^{N} x_i$ 的多次运行可能产生不同结果（为什么？）</li> <li>即使随机种子固定，神经网络训练的多次运行产生的权重也会不同</li> </ul> <p><strong>串行化内存访问</strong></p> <ul> <li>极大地减慢程序速度</li> </ul> <p>让我们运行代码并检查运行时间</p> <h3 id="原子操作测验">原子操作测验</h3> <p>以下操作哪个是正确的？哪个是最快的？</p> <ul> <li>10⁶个线程增量10⁶个元素</li> <li>10⁶个线程原子增量10⁶个元素</li> <li>10⁶个线程增量100个元素</li> <li>10⁶个线程原子增量100个元素</li> <li>10⁷个线程原子增量100个元素</li> </ul> <h2 id="测量速度">测量速度</h2> <h3 id="cpu上测量速度">CPU上测量速度</h3> <p>一个测量CPU时间的简单方法：</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// 测量CPU时间的简单方法</span>
<span class="cp">#include</span> <span class="cpf">&lt;ctime&gt;</span><span class="cp">
</span>
<span class="n">std</span><span class="o">::</span><span class="kt">clock_t</span> <span class="n">start</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">clock</span><span class="p">();</span>
<span class="c1">////////////////////////////</span>
<span class="c1">// 把你的C++代码放在这里 //</span>
<span class="c1">////////////////////////////</span>
<span class="n">std</span><span class="o">::</span><span class="kt">clock_t</span> <span class="n">end</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">clock</span><span class="p">();</span>
<span class="kt">double</span> <span class="n">time_elapsed</span> <span class="o">=</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">/</span> <span class="n">CLOCKS_PER_SEC</span><span class="p">;</span>
</code></pre></div></div> <p>我们能把CUDA kernel函数放在这里来测量时间吗？</p> <p><strong>不行！</strong></p> <p>CPU代码和GPU kernel异步运行。</p> <h3 id="gpu上测量速度">GPU上测量速度</h3> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// 在GPU上测量时间</span>
<span class="n">cudaEvent_t</span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">;</span>
<span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">start</span><span class="p">);</span>
<span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stop</span><span class="p">);</span>

<span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
<span class="c1">///////////////////////////////</span>
<span class="c1">// 把你的CUDA kernel放在这里 //</span>
<span class="c1">///////////////////////////////</span>
<span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">stop</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
<span class="n">cudaEventSynchronize</span><span class="p">(</span><span class="n">stop</span><span class="p">);</span>

<span class="kt">float</span> <span class="n">elapsed</span><span class="p">;</span>
<span class="n">cudaEventElapsedTime</span><span class="p">(</span><span class="o">&amp;</span><span class="n">elapsed</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">);</span>
<span class="n">cudaEventDestroy</span><span class="p">(</span><span class="n">start</span><span class="p">);</span>
<span class="n">cudaEventDestroy</span><span class="p">(</span><span class="n">stop</span><span class="p">);</span>
</code></pre></div></div> <p><strong>注意</strong>：<code class="language-plaintext highlighter-rouge">cudaMemcpy</code> 不是kernel函数。</p> <p>我们应该使用cuda事件API。</p> <p>CPU代码和GPU kernel异步运行。</p> <p>我们可以使用C++实现一个类来简化其用法。</p> <h3 id="pytorch封装的cuda事件">PyTorch封装的CUDA事件</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nc">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nc">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">start</span><span class="p">.</span><span class="nf">record</span><span class="p">()</span>
<span class="c1"># 你要计时的任何操作放在这里
</span><span class="n">end</span><span class="p">.</span><span class="nf">record</span><span class="p">()</span>

<span class="c1"># 等待所有操作完成运行
</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">synchronize</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">start</span><span class="p">.</span><span class="nf">elapsed_time</span><span class="p">(</span><span class="n">end</span><span class="p">))</span>
</code></pre></div></div> <h2 id="并行通信模式-parallel-communication-patterns">并行通信模式 (Parallel Communication Patterns)</h2> <p><strong>并行计算</strong>：许多线程协作解决问题</p> <p>这些线程如何在内存上通信？</p> <h3 id="map一对一">Map：一对一</h3> <p>从特定内存位置读取并写入特定内存位置</p> <h3 id="gather多对一">Gather：多对一</h3> <h3 id="scatter一对多">Scatter：一对多</h3> <p>Scatter是Gather的逆操作</p> <h3 id="stencil">Stencil</h3> <p>从数组中的固定邻域读取输入</p> <ul> <li>Stencil是gather的特殊情况</li> <li>Stencil的反向传播是scatter的特殊情况</li> </ul> <h3 id="transpose">Transpose</h3> <h4 id="矩阵转置">矩阵转置</h4> <h4 id="数据结构转置">数据结构转置</h4> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="n">A</span> <span class="p">{</span>
    <span class="kt">float</span> <span class="n">f</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">i</span><span class="p">;</span>
<span class="p">};</span>
</code></pre></div></div> <p>数组结构（Array of Structures）转换为结构数组（Structure of Arrays）：</p> <h2 id="并行通信模式总结">并行通信模式总结</h2> <h3 id="通信模式概览">通信模式概览</h3> <table> <thead> <tr> <th>模式</th> <th>映射关系</th> <th>典型应用</th> <th>示例</th> </tr> </thead> <tbody> <tr> <td><strong>Map</strong></td> <td>一对一</td> <td>激活函数</td> <td>激活函数</td> </tr> <tr> <td><strong>Transpose</strong></td> <td>一对一</td> <td>数据重排</td> <td> <code class="language-plaintext highlighter-rouge">torch.transpose</code>/<code class="language-plaintext highlighter-rouge">permute</code> </td> </tr> <tr> <td><strong>Gather</strong></td> <td>多对一</td> <td>数据收集</td> <td>索引操作</td> </tr> <tr> <td><strong>Scatter</strong></td> <td>一对多</td> <td>数据分发</td> <td>反向索引</td> </tr> <tr> <td><strong>Stencil</strong></td> <td>多对一</td> <td>卷积操作</td> <td>卷积</td> </tr> <tr> <td><strong>Reduce</strong></td> <td>全对一</td> <td>归约操作</td> <td> <code class="language-plaintext highlighter-rouge">torch.sum</code>/<code class="language-plaintext highlighter-rouge">mean</code> </td> </tr> </tbody> </table> <h2 id="本节课总结">本节课总结</h2> <h3 id="gpu内存">GPU内存</h3> <ul> <li>内存管理；Tensor</li> <li>Local / Shared / Global内存</li> </ul> <h3 id="gpu硬件">GPU硬件</h3> <ul> <li>并行化线程和块</li> <li>SIMT：单指令多线程</li> </ul> <h3 id="同步">同步</h3> <ul> <li>屏障</li> <li>原子操作</li> </ul> <h3 id="通信模式">通信模式</h3> <ul> <li>Map, Gather, Scatter, Stencil, Transpose</li> </ul> <p>这些并行通信模式构成了现代深度学习框架的基础，理解它们对设计高效的GPU程序至关重要。</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesof_ML/">notes of ML</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesofvci/">notes of VCI</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesofaip/">notes of AIP</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesof_aimath/">notes of AI Math Fundamentals</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesof_ICS/">notes of ICS</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 stibiums liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: September 28, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?58fdb075e5aa03fbb8617845abde746c"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>