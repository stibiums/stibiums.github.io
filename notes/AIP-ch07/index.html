<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 人工智能中的编程 - 第7章: 卷积和池化（Convolution and Pooling） | STIBIUMS_WEB </title> <meta name="author" content="stibiums liu"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/touxiang.jpg?68b4199d95528c9129ff55a104244865"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://stibiums.github.io/notes/AIP-ch07/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> STIBIUMS_WEB </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">人工智能中的编程 - 第7章: 卷积和池化（Convolution and Pooling）</h1> <p class="post-meta"> Created on October 17, 2025 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2025   ·   <i class="fa-solid fa-hashtag fa-sm"></i> notes   <i class="fa-solid fa-hashtag fa-sm"></i> AIP   ·   <i class="fa-solid fa-tag fa-sm"></i> AIP </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="alexnet架构">AlexNet架构</h2> <p>AlexNet在2012年的ImageNet竞赛中取得了最佳性能，标志着深度学习在计算机视觉领域的重大突破。</p> <h3 id="alexnet的核心组件">AlexNet的核心组件</h3> <p>AlexNet架构包含以下关键组件：</p> <ul> <li> <strong>卷积层（Convolution）</strong>：提取图像特征</li> <li> <strong>最大池化（Max Pooling）</strong>：降采样特征图</li> <li> <strong>全连接层（Fully Connected Layer）</strong>：高层特征整合</li> <li> <strong>Softmax和损失函数（Softmax &amp; Loss）</strong>：分类和训练</li> </ul> <h2 id="全连接层的优缺点">全连接层的优缺点</h2> <h3 id="全连接层的特点">全连接层的特点</h3> <p><strong>优点</strong>：</p> <ul> <li> <strong>表达能力强</strong>：能够学习任意复杂的特征组合</li> <li> <strong>易于实现</strong>：可以通过GEMM高效实现</li> </ul> <p><strong>缺点</strong>：</p> <ul> <li> <strong>参数量巨大</strong>：200×200→1000的全连接层需要200M参数</li> <li> <strong>缺乏平移不变性/等变性</strong>：对于图像这样的输入，无法利用空间结构</li> </ul> \[y = xA^T\] <p>对于全连接层，输入的不同位置使用完全不同的权重矩阵列，无法共享参数。</p> <h2 id="卷积层">卷积层</h2> <h3 id="卷积层的核心思想">卷积层的核心思想</h3> <p>卷积层通过以下机制解决全连接层的问题：</p> <p><strong>局部连接（Localized Connections）</strong>：</p> <ul> <li>在输入特征图上滑动一个\(k \times k\)的卷积核</li> <li>大幅减少参数数量</li> <li>典型卷积核大小：\(3 \times 3\)</li> </ul> <p><strong>权重共享（Weight Sharing）</strong>：</p> <ul> <li>在所有空间位置共享同一组权重</li> <li>实现平移等变性（Translation Equivariance）</li> <li>输入特征的平移导致输出特征相应平移</li> </ul> <h3 id="卷积操作的数学定义">卷积操作的数学定义</h3> <p>对于输入特征图\(X\)和卷积核\(W\)，输出特征图\(Y\)的计算为：</p> \[y_{i,j} = \sum_{m=0}^{k-1} \sum_{n=0}^{k-1} w_{m,n} \cdot x_{i+m, j+n}\] <h2 id="卷积层的边界处理">卷积层的边界处理</h2> <h3 id="常见的边界处理方法">常见的边界处理方法</h3> <p><strong>1. 忽略边界位置（Ignore These Locations）</strong>：</p> <ul> <li>不计算边界列的卷积结果</li> <li>输出尺寸会缩小</li> </ul> <p><strong>2. 零填充（Pad with Zeros）</strong>：</p> <ul> <li>在图像边界外填充零值</li> <li>保持输出尺寸不变</li> <li>最常用的方法</li> </ul> <p><strong>3. 周期性假设（Assume Periodicity）</strong>：</p> <ul> <li>顶行环绕到底行</li> <li>最左列环绕到最右列</li> <li>适用于具有周期性的数据</li> </ul> <p><strong>4. 反射边界（Reflect Border）</strong>：</p> <ul> <li>通过镜像边界复制行/列</li> <li>保持边界的连续性</li> </ul> <h3 id="pytorch中的填充">PyTorch中的填充</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">constant</span><span class="sh">'</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre></div></div> <p>模式选项：<code class="language-plaintext highlighter-rouge">'constant'</code>、<code class="language-plaintext highlighter-rouge">'reflect'</code>、<code class="language-plaintext highlighter-rouge">'replicate'</code> 或 <code class="language-plaintext highlighter-rouge">'circular'</code></p> <h2 id="pytorch中的卷积">PyTorch中的卷积</h2> <h3 id="多通道卷积">多通道卷积</h3> <p>PyTorch中的卷积将多通道输入映射到多通道输出：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                           <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="err">→</span> <span class="n">Tensor</span>
</code></pre></div></div> <p><strong>参数说明</strong>：</p> <ul> <li> <code class="language-plaintext highlighter-rouge">input</code>：输入张量，形状为\([N, C_{in}, H, W]\)</li> <li> <code class="language-plaintext highlighter-rouge">weight</code>：卷积核，形状为\([C_{out}, C_{in}, K_H, K_W]\)</li> <li> <code class="language-plaintext highlighter-rouge">bias</code>：可选的偏置张量，形状为\([C_{out}]\)</li> <li> <code class="language-plaintext highlighter-rouge">stride</code>：卷积核的步长</li> <li> <code class="language-plaintext highlighter-rouge">padding</code>：输入两侧的隐式填充</li> </ul> <h3 id="输出尺寸计算">输出尺寸计算</h3> <p>对于输入尺寸\(H \times W\)，卷积核尺寸\(K \times K\)，填充\(P\)，步长\(S\)：</p> \[H_{out} = \left\lfloor \frac{H + 2P - K}{S} \right\rfloor + 1\] \[W_{out} = \left\lfloor \frac{W + 2P - K}{S} \right\rfloor + 1\] <h2 id="步长卷积和池化">步长卷积和池化</h2> <h3 id="生成不同分辨率的特征">生成不同分辨率的特征</h3> <p>有两种主要方法来降低特征图的空间分辨率：</p> <p><strong>方法1：池化层</strong></p> <ul> <li>使用最大池化或平均池化聚合信息</li> <li>典型配置：\(2 \times 2\)窗口，步长2</li> </ul> <p><strong>方法2：步长卷积</strong></p> <ul> <li>卷积核以大于1的步长（stride）移动</li> <li>同时实现下采样和特征提取</li> </ul> <h2 id="分组卷积">分组卷积</h2> <h3 id="分组卷积的动机">分组卷积的动机</h3> <p>对于大的输入/输出通道数，卷积核\([C_{out}, C_{in}, K_H, K_W]\)仍然包含大量参数，导致：</p> <ul> <li>过拟合风险</li> <li>计算速度慢</li> </ul> <h3 id="分组卷积原理">分组卷积原理</h3> <p><strong>核心思想</strong>：将通道分组，每组输出通道只依赖对应组的输入通道</p> <p><strong>深度可分离卷积（Depthwise Convolution）</strong>：</p> <ul> <li>组数等于通道数</li> <li>每个通道独立卷积</li> <li>广泛应用于MobileNets等轻量级网络</li> </ul> <p><strong>参数量对比</strong>：</p> <ul> <li>标准卷积：\(C_{out} \times C_{in} \times K \times K\)</li> <li>深度可分离卷积：\(C \times K \times K\)</li> </ul> <h2 id="卷积的朴素实现">卷积的朴素实现</h2> <h3 id="多重循环实现">多重循环实现</h3> <p>对于输入形状\([N, C_i, H, W]\)，输出形状\([N, C_o, H, W]\)，卷积核形状\([C_o, C_i, K, K]\)：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">N</span>
    <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">W</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">H</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">K</span>
                <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">K</span>
                    <span class="k">for</span> <span class="n">c0</span> <span class="ow">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">Co</span>
                        <span class="k">for</span> <span class="n">c1</span> <span class="ow">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">Ci</span>
                            <span class="nf">output</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c0</span><span class="p">)</span> <span class="o">+=</span>
                                <span class="nf">input</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">w</span><span class="o">+</span><span class="n">k</span><span class="p">,</span> <span class="n">h</span><span class="o">+</span><span class="n">q</span><span class="p">,</span> <span class="n">c1</span><span class="p">)</span> <span class="o">*</span> <span class="nf">kernel</span><span class="p">(</span><span class="n">c0</span><span class="p">,</span> <span class="n">c1</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
</code></pre></div></div> <p><strong>问题</strong>：</p> <ul> <li>七重循环，难以优化</li> <li>比PyTorch慢1000倍以上</li> </ul> <h2 id="卷积作为矩阵乘法">卷积作为矩阵乘法</h2> <h3 id="版本1稀疏矩阵-向量乘法spmv">版本1：稀疏矩阵-向量乘法（SpMV）</h3> <p>将卷积写成稀疏矩阵与向量的乘积：</p> \[Y = \hat{W}X\] <p>其中\(\hat{W}\)是从卷积核\(W\)构造的稀疏矩阵。</p> <p><strong>前向传播</strong>：</p> <ol> <li>从\(W\)构造\(\hat{W}\)</li> <li>执行SpMV：\(Y = \hat{W}X\)</li> </ol> <p><strong>反向传播</strong>：</p> <ul> <li>\(\frac{\partial L}{\partial X} = \hat{W}^T \times \frac{\partial L}{\partial Y}\)（转置卷积）</li> <li>\(\frac{\partial L}{\partial W} \leftarrow \frac{\partial L}{\partial \hat{W}}\)（需要排序和分段归约）</li> </ul> <h3 id="版本2显式gemmexplicit-gemm">版本2：显式GEMM（Explicit GEMM）</h3> <p>通过im2col将卷积转换为密集矩阵乘法：</p> \[Y = \hat{X}W\] <p><strong>im2col操作</strong>：</p> <ul> <li>将输入的局部窗口展开成矩阵的列</li> <li>构造的\(\hat{X}\)矩阵尺寸大，但可以利用高度优化的GEMM</li> </ul> <p><strong>前向传播</strong>：</p> <ol> <li>通过im2col从\(X\)构造\(\hat{X}\)</li> <li>执行GEMM：\(Y = \hat{X}W\)</li> </ol> <p><strong>反向传播</strong>：</p> <ul> <li>\(\frac{\partial L}{\partial W} = \frac{\partial L}{\partial Y} \times \hat{X}^T\)（GEMM）</li> <li>\(\frac{\partial L}{\partial X} \leftarrow \frac{\partial L}{\partial \hat{X}}\)（col2im，使用原子操作）</li> </ul> <p><strong>优点</strong>：</p> <ul> <li>实现简单</li> <li>极其高效</li> </ul> <p><strong>缺点</strong>：</p> <ul> <li>消耗大量内存</li> <li>每个输入元素被复制\(K \times K\)次</li> </ul> <h3 id="版本3隐式gemmimplicit-gemm">版本3：隐式GEMM（Implicit GEMM）</h3> <p><strong>核心思想</strong>：</p> <ul> <li>在数据从全局内存加载到共享内存时，动态构造卷积矩阵的tile</li> <li>利用现有的warp级GEMM组件累积卷积结果</li> <li>更节省内存和计算</li> </ul> <p>详见：<a href="https://github.com/NVIDIA/cutlass/blob/main/media/docs/implicit_gemm_convolution.md" rel="external nofollow noopener" target="_blank">NVIDIA CUTLASS - Implicit GEMM Convolution</a></p> <h2 id="使用cuda实现卷积">使用CUDA实现卷积</h2> <h3 id="实现步骤">实现步骤</h3> <ol> <li><strong>实现im2col和col2im</strong></li> <li> <strong>结合im2col和GEMM实现前向传播</strong>：\(Y = \hat{X}W\)</li> <li> <strong>结合im2col和GEMM实现权重的反向传播</strong>：\(\frac{\partial L}{\partial W} = \frac{\partial L}{\partial Y} \times \hat{X}^T\)</li> <li> <strong>结合col2im和GEMM实现输入的反向传播</strong>：\(\frac{\partial L}{\partial \hat{X}} = W^T \times \frac{\partial L}{\partial Y}\)</li> <li><strong>使用GEMM添加卷积偏置</strong></li> </ol> <h3 id="偏置项处理">偏置项处理</h3> <p>偏置项也可以看作一个神经网络层，通过广播机制添加到每个空间位置。</p> <h2 id="深度可分离卷积">深度可分离卷积</h2> <h3 id="特点和应用">特点和应用</h3> <p><strong>应用场景</strong>：</p> <ul> <li>MobileNets：广泛应用于移动和嵌入式视觉应用</li> <li>显著更快且包含更少的可训练参数</li> </ul> <p><strong>参数和计算量对比</strong>：</p> <p>对于输入形状\([N, C, H, W]\)和卷积核大小\([K, K]\)：</p> <ul> <li> <strong>标准卷积</strong>：每个输出元素需要\(K \times K \times C\)次乘法，卷积核形状\([C, C, K, K]\)</li> <li> <strong>深度可分离卷积</strong>：每个输出元素只需\(K \times K\)次乘法，卷积核形状\([C, K, K]\)</li> </ul> <h3 id="深度可分离卷积是内存受限的">深度可分离卷积是内存受限的</h3> <p><strong>特点</strong>：</p> <ul> <li>工作复杂度比标准卷积低\(C\)倍（例如128倍）</li> <li>对于输入形状\([N, C_i, H, W]\)，输出形状\([N, C_o, H, W]\)，卷积核形状\([C, K, K]\)，只需要6重循环</li> <li>应该优先改进内存复杂度</li> </ul> <h3 id="cuda实现">CUDA实现</h3> <div class="language-cuda highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">n</span> <span class="n">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">N</span>
    <span class="k">for</span> <span class="n">c</span> <span class="n">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">C</span>
        <span class="k">for</span> <span class="n">h</span> <span class="n">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">H</span>
            <span class="k">for</span> <span class="n">w</span> <span class="n">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">W</span>
                <span class="k">for</span> <span class="n">k</span> <span class="n">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">K</span>
                    <span class="k">for</span> <span class="n">q</span> <span class="n">in</span> <span class="mf">1.</span><span class="p">.</span><span class="n">K</span>
                        <span class="n">output</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="o">+=</span>
                            <span class="n">input</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">w</span><span class="o">+</span><span class="n">k</span><span class="p">,</span> <span class="n">h</span><span class="o">+</span><span class="n">q</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="o">*</span> <span class="n">kernel</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
</code></pre></div></div> <p><strong>实现策略</strong>：</p> <ul> <li>用CUDA kernel并行化前4个循环</li> <li>每个线程负责一个输出元素</li> <li>典型情况下\(K=3\)，每个线程执行9次乘法</li> </ul> <p><strong>前向传播和输入梯度</strong>：实现相似</p> <p><strong>权重梯度计算</strong>：相对困难</p> <ul> <li>需要将梯度归约到\(C \times K \times K\)个参数</li> <li>利用共享内存+归约操作</li> </ul> <h2 id="池化层">池化层</h2> <h3 id="最大池化max-pooling">最大池化（Max Pooling）</h3> <p>最大池化在每个通道上独立进行空间降采样：</p> <p><strong>常见配置</strong>：</p> <ul> <li>核大小：\(2 \times 2\)</li> <li>步长：2</li> <li>输出尺寸为输入的1/2</li> </ul> <h3 id="pytorch中的最大池化">PyTorch中的最大池化</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">max_pool2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                               <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <p><strong>参数</strong>：</p> <ul> <li> <code class="language-plaintext highlighter-rouge">input</code>：输入张量 (minibatch, in_channels, \(iH\), \(iW\))</li> <li> <code class="language-plaintext highlighter-rouge">kernel_size</code>：池化区域的大小，可以是单个数字或元组 (kH, kW)</li> <li> <code class="language-plaintext highlighter-rouge">stride</code>：池化操作的步长，默认等于kernel_size</li> <li> <code class="language-plaintext highlighter-rouge">padding</code>：隐式负无穷填充</li> <li> <code class="language-plaintext highlighter-rouge">dilation</code>：滑动窗口内元素之间的步长</li> </ul> <h3 id="最大池化的前向传播">最大池化的前向传播</h3> <div class="language-cuda highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">__global__</span> <span class="kt">void</span> <span class="nf">max_pool_forward</span><span class="p">(</span>
    <span class="kt">float</span><span class="o">*</span> <span class="n">in_data</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nthreads</span><span class="p">,</span> <span class="kt">int</span> <span class="n">num</span><span class="p">,</span> <span class="kt">int</span> <span class="n">channels</span><span class="p">,</span>
    <span class="kt">int</span> <span class="n">in_h</span><span class="p">,</span> <span class="kt">int</span> <span class="n">in_w</span><span class="p">,</span> <span class="kt">int</span> <span class="n">out_h</span><span class="p">,</span> <span class="kt">int</span> <span class="n">out_w</span><span class="p">,</span> <span class="kt">int</span> <span class="n">kernel_h</span><span class="p">,</span>
    <span class="kt">int</span> <span class="n">kernel_w</span><span class="p">,</span> <span class="kt">int</span> <span class="n">stride_h</span><span class="p">,</span> <span class="kt">int</span> <span class="n">stride_w</span><span class="p">,</span> <span class="kt">int</span> <span class="n">pad_h</span><span class="p">,</span>
    <span class="kt">int</span> <span class="n">pad_w</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">out_data</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">out_mask</span><span class="p">)</span> <span class="p">{</span>

    <span class="n">CUDA_KERNEL_LOOP</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">nthreads</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">index</span> <span class="o">/</span> <span class="n">out_w</span> <span class="o">/</span> <span class="n">out_h</span> <span class="o">/</span> <span class="n">channels</span><span class="p">;</span>
        <span class="kt">int</span> <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="n">index</span> <span class="o">/</span> <span class="n">out_w</span> <span class="o">/</span> <span class="n">out_h</span><span class="p">)</span> <span class="o">%</span> <span class="n">channels</span><span class="p">;</span>
        <span class="kt">int</span> <span class="n">ph</span> <span class="o">=</span> <span class="p">(</span><span class="n">index</span> <span class="o">/</span> <span class="n">out_w</span><span class="p">)</span> <span class="o">%</span> <span class="n">out_h</span><span class="p">;</span>
        <span class="kt">int</span> <span class="n">pw</span> <span class="o">=</span> <span class="n">index</span> <span class="o">%</span> <span class="n">out_w</span><span class="p">;</span>

        <span class="c1">// 对每个局部窗口实现最大池化</span>
        <span class="c1">// 将最大值和掩码存储到out_data[index]和out_mask[index]</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p><strong>实现要点</strong>：</p> <ul> <li>每个线程负责一个局部窗口</li> <li>同时记录最大值位置（掩码）用于反向传播</li> </ul> <h3 id="最大池化的反向传播">最大池化的反向传播</h3> <p><strong>梯度传播规则</strong>：</p> <p>\(\max(x_1, x_2, \ldots, x_k)\)的梯度为：</p> <ul> <li>对于最大值位置：梯度传递</li> <li>对于其他位置：梯度为0</li> </ul> <p><strong>反池化（Unpooling）</strong>：</p> <ul> <li>根据前向传播保存的掩码将梯度放回原位置</li> <li>其他位置填充0</li> <li>广泛用于图像分割任务</li> </ul> <h3 id="stencil并行模式">Stencil并行模式</h3> <p>卷积和池化操作属于Stencil模式：</p> <ul> <li> <strong>Gather（多对一）</strong>：卷积/池化的前向传播</li> <li> <strong>Scatter（一对多）</strong>：卷积/池化的反向传播</li> <li> <strong>Stencil（固定邻域的多对一）</strong>：具有固定邻域模式的gather</li> </ul> <p><strong>实现策略</strong>：当邻域尺寸较小时，为每个输出元素启动一个线程。</p> <h2 id="softmax函数">Softmax函数</h2> <h3 id="softmax的定义">Softmax的定义</h3> <p>Softmax函数将网络预测转换为概率分布：</p> \[S(a) : \begin{bmatrix} a_1 \\ a_2 \\ \vdots \\ a_N \end{bmatrix} \rightarrow \begin{bmatrix} S_1 \\ S_2 \\ \vdots \\ S_N \end{bmatrix}, \quad S_j = \frac{e^{a_j}}{\sum_{k=1}^N e^{a_k}}, \quad \forall j \in 1..N\] <p><strong>示例</strong>：</p> <ul> <li> \[[1.0, 2.0, 3.0] \rightarrow [0.09, 0.24, 0.67]\] </li> <li> \[[1.0, 2.0, 5.0] \rightarrow [0.02, 0.05, 0.93]\] </li> </ul> <h3 id="数值稳定性">数值稳定性</h3> <p><strong>朴素实现</strong>：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">exps</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">exps</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">exps</span><span class="p">)</span>
</code></pre></div></div> <p><strong>问题</strong>：对于大的输入值会溢出</p> <p><strong>稳定实现</strong>：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">stable_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">exps</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">exps</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">exps</span><span class="p">)</span>
</code></pre></div></div> <p><strong>数学原理</strong>：</p> \[S_j = \frac{e^{a_j}}{\sum_{k=1}^N e^{a_k}} = \frac{e^{a_j+D}}{\sum_{k=1}^N e^{a_k+D}}, \quad D = -\max(a_1, a_2, \cdots, a_N)\] <h3 id="使用cuda实现softmax">使用CUDA实现Softmax</h3> <p>对于输入\([N, C]\)，输出\([N, C]\)（\(C\)通常为10，用于MNIST分类）：</p> <ol> <li> <strong>计算每行的最大值</strong>：使用max归约，或每行一个线程直接计算</li> <li> <strong>减去最大值</strong>（Map操作）</li> <li> <strong>计算每个元素的指数</strong>（Map操作）</li> <li> <strong>对每行求和计算归一化因子</strong>：使用sum归约，或每行一个线程直接计算</li> <li> <strong>归一化结果</strong>（Map操作）</li> </ol> <h3 id="softmax的梯度">Softmax的梯度</h3> <p>Softmax的Jacobian矩阵：</p> \[\frac{\partial p_i}{\partial o_j} = \begin{cases} p_i(1-p_j) &amp; \text{if } i = j \\ -p_j \cdot p_i &amp; \text{if } i \neq j \end{cases}\] <p>其中\(p_i \triangleq S_i\)</p> <h2 id="交叉熵损失">交叉熵损失</h2> <h3 id="交叉熵损失的定义">交叉熵损失的定义</h3> <p>交叉熵损失衡量预测概率分布和真实概率分布之间的距离：</p> \[H(y, p) = -\sum_i y_i \log(p_i)\] <h3 id="python实现">Python实现</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">log_likelihood</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="nf">range</span><span class="p">(</span><span class="n">m</span><span class="p">),</span> <span class="n">y</span><span class="p">])</span>  <span class="c1"># map
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">log_likelihood</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span>  <span class="c1"># reduce mean
</span>    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></div> <h3 id="交叉熵损失与softmax的梯度">交叉熵损失与Softmax的梯度</h3> <p><strong>组合梯度计算</strong>：</p> \[L = -\sum_i y_i \log(p_i)\] \[\frac{\partial L}{\partial o_i} = p_i - y_i\] <p><strong>推导过程</strong>：</p> \[\frac{\partial L}{\partial o_i} = -\sum_k y_k \frac{\partial \log(p_k)}{\partial o_i} = -\sum_k y_k \frac{1}{p_k} \times \frac{\partial p_k}{\partial o_i}\] <p>利用Softmax的梯度公式，最终得到简洁的结果：\(p_i - y_i\)</p> <p><strong>实现优势</strong>：</p> <ul> <li>直接计算\(p - y\)，无需显式计算Jacobian矩阵</li> <li>数值稳定且计算高效</li> </ul> <h2 id="转置卷积反卷积">转置卷积（反卷积）</h2> <h3 id="用途和原理">用途和原理</h3> <p><strong>应用场景</strong>：</p> <ul> <li>上采样特征图</li> <li>广泛应用于图像分割和图像生成</li> </ul> <p><strong>实现方法</strong>：</p> <ul> <li>交换卷积的前向传播和反向传播</li> <li>前向传播使用：\(\frac{\partial L}{\partial \hat{X}} = W^T \times \frac{\partial L}{\partial Y}\)</li> </ul> <p><strong>示例</strong>：</p> <p>步长卷积： \(\text{Input}(6 \times 6) \xrightarrow[\text{stride 2}]{\text{conv } 3 \times 3} \text{Output}(2 \times 2)\)</p> <p>转置卷积： \(\text{Input}(2 \times 2) \xrightarrow[\text{stride 2}]{\text{transposed conv } 3 \times 3} \text{Output}(6 \times 6)\)</p> <p>转置卷积通过在输入之间插入零值和应用常规卷积来实现上采样效果。</p> <h2 id="总结">总结</h2> <h3 id="卷积和池化的关键概念">卷积和池化的关键概念</h3> <ol> <li> <p><strong>卷积层优势</strong>：</p> <ul> <li>参数共享减少模型大小</li> <li>平移等变性适合图像处理</li> <li>局部连接捕获空间结构</li> </ul> </li> <li> <p><strong>实现策略</strong>：</p> <ul> <li>im2col + GEMM：简单高效但内存密集</li> <li>隐式GEMM：内存高效的高性能实现</li> <li>深度可分离卷积：轻量级网络的选择</li> </ul> </li> <li> <p><strong>池化层作用</strong>：</p> <ul> <li>空间降采样</li> <li>增加感受野</li> <li>提供一定的平移不变性</li> </ul> </li> <li> <p><strong>Softmax和损失</strong>：</p> <ul> <li>数值稳定性很重要</li> <li>Softmax + 交叉熵的组合梯度简洁高效</li> </ul> </li> <li> <p><strong>并行模式</strong>：</p> <ul> <li>Stencil模式适用于固定邻域操作</li> <li>Map和Reduce操作的组合</li> </ul> </li> </ol> <p>通过理解这些核心概念和实现技术，我们可以构建高效的深度学习系统，充分利用GPU的计算能力。</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesof_ML/">notes of ML</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesofvci/">notes of VCI</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesofaip/">notes of AIP</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesof_aimath/">notes of AI Math Fundamentals</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesof_ICS/">notes of ICS</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 stibiums liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: October 21, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?58fdb075e5aa03fbb8617845abde746c"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>