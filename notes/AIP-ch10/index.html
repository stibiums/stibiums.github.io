<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 人工智能中的编程 - 第10章: 计算图（Computational Graph） | STIBIUMS_WEB </title> <meta name="author" content="stibiums liu"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/touxiang.jpg?68b4199d95528c9129ff55a104244865"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://stibiums.github.io/notes/AIP-ch10/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> STIBIUMS_WEB </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/notes/">notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">人工智能中的编程 - 第10章: 计算图（Computational Graph）</h1> <p class="post-meta"> Created on October 30, 2025 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2025   ·   <i class="fa-solid fa-hashtag fa-sm"></i> notes   <i class="fa-solid fa-hashtag fa-sm"></i> AIP   <i class="fa-solid fa-hashtag fa-sm"></i> computational-graph   <i class="fa-solid fa-hashtag fa-sm"></i> DAG   ·   <i class="fa-solid fa-tag fa-sm"></i> AIP </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="计算图在-ai-框架中的地位">计算图在 AI 框架中的地位</h2> <p>计算图（Computational Graph）是现代 AI 框架的核心数据结构。它为高级编程语言（如 Python）和底层计算引擎（C/C++/CUDA）之间提供了统一的接口，使得用户可以用简洁的高级语言编写神经网络，同时框架可以在底层进行优化和加速。</p> <h3 id="计算图的四大任务">计算图的四大任务</h3> <p>计算图需要支持以下关键功能：</p> <ol> <li> <p><strong>计算表示</strong>（Computational Representation）</p> <ul> <li>统一的数据结构表示复杂的神经网络计算</li> <li>支持前向计算和反向求导</li> </ul> </li> <li> <p><strong>自动求导</strong>（Automatic Differentiation）</p> <ul> <li>自动计算神经网络中所有参数的梯度</li> <li>支持前向模式和反向模式自动微分</li> </ul> </li> <li> <p><strong>变量生命周期分析</strong>（Variable Lifecycle）</p> <ul> <li>精确追踪中间张量的生命周期</li> <li>辅助框架优化内存管理</li> </ul> </li> <li> <p><strong>程序优化执行</strong>（Program Optimization）</p> <ul> <li>对计算图进行优化和调度</li> <li>批处理、缓存、操作融合等优化</li> </ul> </li> </ol> <h2 id="什么是计算图">什么是计算图</h2> <p>计算图（Computational Graph, CG）是一种用<strong>有向无环图</strong>（DAG, Directed Acyclic Graph）表示神经网络和梯度计算的方式。</p> <h3 id="图的基本组成">图的基本组成</h3> <p>计算图由以下基本元素组成：</p> <ul> <li> <strong>节点（Nodes）</strong>：代表操作符（Operators）</li> <li> <strong>边（Edges）</strong>：代表数据流（张量的流动）</li> <li> <strong>特殊操作符</strong>：控制流操作（if/else、for/while）</li> <li> <strong>特殊边</strong>：依赖边（表示操作之间的依赖关系）</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> {% include figure.liquid loading="eager" path="assets/img/notes_img/AIP-ch10/computational_graph_dag.png" title="计算图的前向和反向表示" class="img-fluid rounded z-depth-1" zoomable=true %} </div> </div> <p>上图展示了计算图的两个视图：</p> <ul> <li> <strong>左图</strong>：前向计算图，展示数据从输入流向损失函数的过程</li> <li> <strong>右图</strong>：前向和反向的完整计算图，包括反向传播的梯度流动</li> </ul> <h2 id="计算图中的操作符dag-节点">计算图中的操作符（DAG 节点）</h2> <h3 id="张量操作tensor-operations">张量操作（Tensor Operations）</h3> <p>用于张量的基本操作：</p> <ul> <li>Reshape、Concat、Matmul、Transpose、Slice 等</li> <li>通常是元素级（element-wise）或矩阵级（matrix-level）操作</li> </ul> <h3 id="网络操作network-operations">网络操作（Network Operations）</h3> <p>用于神经网络的操作：</p> <ul> <li> <strong>损失函数</strong>（Loss）：CrossEntropy、MSE 等</li> <li> <strong>梯度计算</strong>（Grads）：自动微分产生的反向操作</li> <li> <strong>优化器</strong>（Optimizers）：SGD、Adam 等参数更新操作</li> </ul> <h3 id="数据管理data-management">数据管理（Data Management）</h3> <p>用于数据处理的操作：</p> <ul> <li>Batch、Pre-fetch、Tile、Crop、Normalization 等</li> <li>用于高效处理和预处理数据</li> </ul> <h3 id="控制流操作control-flow">控制流操作（Control Flow）</h3> <p>用于程序控制的操作：</p> <ul> <li> <strong>条件分支</strong>：if/else、switch</li> <li> <strong>循环</strong>：for/while、while_loop</li> <li>提供程序的动态控制能力</li> </ul> <h2 id="计算图中的张量dag-边">计算图中的张量（DAG 边）</h2> <h3 id="1-ndarray多维数组">1. Ndarray（多维数组）</h3> <p>最常见的张量表示方式，适合 SIMT（Single-Instruction Multiple-Thread）并行计算。</p> <p><strong>特点：</strong></p> <ul> <li>密集存储，所有元素都占用内存</li> <li>GPU 友好，支持高效的并行计算</li> <li>适合卷积、矩阵乘法等常见操作</li> </ul> <p><strong>例子：</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 形状为 (batch, height, width, channels) 的图像数据
</span><span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</code></pre></div></div> <h3 id="2-ragged-tensors不规则张量">2. Ragged Tensors（不规则张量）</h3> <p>用于表示长度不同的序列数据。</p> <p><strong>特点：</strong></p> <ul> <li>可变长度的行或列</li> <li>适合处理文本、点云等不规则数据</li> <li>节省内存，避免填充造成的浪费</li> </ul> <p><strong>例子：</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>句子1: [词1, 词2, 词3, 词4, 词5]        (长度5)
句子2: [词1, 词2, 词3]                  (长度3)
句子3: [词1, 词2, 词3, 词4]             (长度4)
</code></pre></div></div> <h3 id="3-sparse-tensors稀疏张量">3. Sparse Tensors（稀疏张量）</h3> <p>用于表示大量零元素的矩阵。</p> <p><strong>存储格式：</strong> 坐标列表（Coordinate List）</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>行索引：[0, 0, 0, 2, 2, 3, 4, 4, 4]
列索引：[0, 2, 4, 1, 4, 2, 0, 2, 4]
值列表：[1, 3, 5, 4, 8, 7, 6, 2, 9]
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> {% include figure.liquid loading="eager" path="assets/img/notes_img/AIP-ch10/tensor_types.png" title="三种张量表示方式" class="img-fluid rounded z-depth-1" zoomable=true %} </div> </div> <p><strong>应用场景：</strong></p> <ul> <li>图神经网络中的邻接矩阵</li> <li>推荐系统中的用户-物品交互矩阵</li> <li>自然语言处理中的稀疏特征表示</li> </ul> <h2 id="计算图中的特殊边">计算图中的特殊边</h2> <h3 id="依赖边dependency-edges">依赖边（Dependency Edges）</h3> <p>除了数据边（tensor edges），计算图还包含特殊的依赖边，用于表示操作之间的执行依赖关系。</p> <p><strong>分类：</strong></p> <ol> <li> <p><strong>直接数据依赖</strong></p> <ul> <li>操作 A 使用操作 B 的输出</li> <li>A 和 B 之间有直接的数据边</li> </ul> </li> <li> <p><strong>间接依赖</strong></p> <ul> <li>操作 A 依赖操作 B，但不直接使用 B 的输出</li> <li>例如：A 和 B 共享同一个 GPU 缓冲区</li> </ul> </li> <li> <p><strong>独立操作</strong></p> <ul> <li>A 和 B 之间没有任何边</li> <li>可以并行执行</li> </ul> </li> </ol> <p><strong>作用：</strong></p> <ul> <li>帮助图调度器（Graph Dispatcher）确定操作的执行顺序</li> <li>优化内存管理和资源利用</li> </ul> <p><strong>具体例子：</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor2</span> <span class="o">=</span> <span class="nf">opA</span><span class="p">(</span><span class="n">tensor1</span><span class="p">)</span>
<span class="n">tensor3</span> <span class="o">=</span> <span class="nf">opB</span><span class="p">(</span><span class="n">tensor2</span><span class="p">)</span>
<span class="n">tensor4</span> <span class="o">=</span> <span class="nf">opC</span><span class="p">(</span><span class="n">tensor2</span><span class="p">,</span> <span class="n">tensor3</span><span class="p">)</span>
</code></pre></div></div> <p>在无依赖的情况下，opB 和 opC 可以并行执行（因为都依赖 tensor2）。但如果 opA 和 opB 共享 GPU 缓冲区，则需要添加依赖边，确保 opA 先完成再执行 opB。</p> <h2 id="计算图中的特殊操作符">计算图中的特殊操作符</h2> <h3 id="控制流操作control-flow-operators">控制流操作（Control-flow Operators）</h3> <p>现代 AI 框架支持三种方式来集成控制流操作：</p> <h4 id="1-后端原生支持native-backend-support">1. 后端原生支持（Native Backend Support）</h4> <p>AI 框架在底层直接提供控制流操作的支持。</p> <p><strong>优点：</strong></p> <ul> <li>控制流与数据流无缝集成</li> <li>执行效率高</li> </ul> <p><strong>例子：</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># TensorFlow 原生支持
</span><span class="n">if_op</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cond</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">output_true</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">output_false</span><span class="p">)</span>
</code></pre></div></div> <h4 id="2-前端语言控制流frontend-language-control-flow">2. 前端语言控制流（Frontend Language Control Flow）</h4> <p>框架直接利用前端语言（如 Python）的控制流逻辑。</p> <p><strong>优点：</strong></p> <ul> <li>编程灵活性高</li> <li>用户可以使用熟悉的 Python 语法</li> </ul> <p><strong>例子：</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PyTorch 动态图 - 使用 Python 的 if
</span><span class="k">if</span> <span class="n">condition</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nf">model1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nf">model2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <p><strong>缺点：</strong></p> <ul> <li>需要在前后端语言之间切换</li> <li>可能运行在不同的硬件上</li> </ul> <h4 id="3-后端解析子图backend-parsing-subgraphs">3. 后端解析子图（Backend Parsing Subgraphs）</h4> <p>后端将前端的控制流逻辑解析为多个子图。</p> <p><strong>优点：</strong></p> <ul> <li>可以对控制流进行优化</li> <li>支持图级优化</li> </ul> <p><strong>例子：</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 解析为两个分支的子图
# Subgraph1: if 分支
# Subgraph2: else 分支
# Merge: 合并两个分支结果
</span></code></pre></div></div> <h2 id="编程范式与计算图的构建">编程范式与计算图的构建</h2> <h3 id="声明式编程declarative-programmingvs-命令式编程imperative-programming">声明式编程（Declarative Programming）vs 命令式编程（Imperative Programming）</h3> <p>构建计算图有两种主要的编程范式：</p> <h4 id="声明式编程---静态图static-graph">声明式编程 - 静态图（Static Graph）</h4> <p><strong>代表框架：</strong> TensorFlow 1.x</p> <p><strong>工作流程：</strong></p> <ol> <li>先定义所有操作和数据流</li> <li>构建完整的计算图</li> <li>通过 Session 执行图</li> </ol> <p><strong>特点：</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># TensorFlow 1.x 示例
</span><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="c1"># 定义计算图
</span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">random_normal</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>

<span class="c1"># 执行计算图
</span><span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">global_variables_initializer</span><span class="p">())</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">data</span><span class="p">})</span>
</code></pre></div></div> <p><strong>优点：</strong></p> <ul> <li>✓ 可以进行多种优化策略</li> <li>✓ 执行效率高</li> <li>✓ 易于部署</li> </ul> <p><strong>缺点：</strong></p> <ul> <li>✗ 编程不灵活</li> <li>✗ 难以支持控制流（if/else、for/while）</li> <li>✗ 调试困难</li> </ul> <h4 id="命令式编程---动态图dynamic-graph">命令式编程 - 动态图（Dynamic Graph）</h4> <p><strong>代表框架：</strong> PyTorch</p> <p><strong>工作流程：</strong></p> <ol> <li>动态执行代码</li> <li>在执行时记录操作和数据流</li> <li>构建计算图</li> </ol> <p><strong>特点：</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PyTorch 示例
</span><span class="kn">import</span> <span class="n">torch</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># 直接计算，自动构建图
</span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>

<span class="c1"># 反向传播
</span><span class="n">loss</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span>
<span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
</code></pre></div></div> <p><strong>优点：</strong></p> <ul> <li>✓ 非常灵活，支持 Python 的所有语法</li> <li>✓ 易于调试和理解</li> <li>✓ 轻松支持控制流</li> </ul> <p><strong>缺点：</strong></p> <ul> <li>✗ 优化空间有限</li> <li>✗ 执行性能相对较低</li> <li>✗ 不易部署</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> {% include figure.liquid loading="eager" path="assets/img/notes_img/AIP-ch10/paradigms_comparison.png" title="编程范式对比" class="img-fluid rounded z-depth-1" zoomable=true %} </div> </div> <h3 id="静态图与动态图的融合">静态图与动态图的融合</h3> <p>现代 AI 框架（PyTorch 2.0、TensorFlow 2.0、JAX、MindSpore）采用<strong>融合策略</strong>：</p> <p><strong>全局：动态图</strong></p> <ul> <li>提供灵活的编程接口</li> <li>支持 Python 的控制流和递归</li> </ul> <p><strong>局部：静态子图</strong></p> <ul> <li>通过函数式编程（Functional Programming）或图捕获</li> <li>在特定函数中生成静态子图进行优化</li> </ul> <p><strong>优点：</strong></p> <ul> <li>✓ 编码和调试的灵活性（动态图）</li> <li>✓ 执行和部署的效率（静态图）</li> </ul> <h2 id="图捕获graph-capture">图捕获（Graph Capture）</h2> <p>从动态图生成静态子图的关键技术是<strong>图捕获</strong>，主要分为两大类：</p> <h3 id="方法-1-跟踪法trace-based">方法 1: 跟踪法（Trace-Based）</h3> <p><strong>原理：</strong> 运行函数一次，记录所有操作</p> <p><strong>过程：</strong></p> <ol> <li>用样本输入执行函数</li> <li>记录执行过程中的所有操作</li> <li>将记录转换为计算图</li> </ol> <p><strong>代表实现：</strong></p> <ul> <li> <code class="language-plaintext highlighter-rouge">torch.jit.trace()</code>：记录执行轨迹</li> <li> <code class="language-plaintext highlighter-rouge">torch.fx.symbolic_trace()</code>：符号跟踪</li> </ul> <p><strong>示例：</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="nf">return </span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">.</span><span class="nf">pow</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># 跟踪方式1：JIT tracing
</span><span class="n">traced_f</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">trace</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># 跟踪方式2：Symbolic tracing
</span><span class="n">fx_f</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">fx</span><span class="p">.</span><span class="nf">symbolic_trace</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="c1"># 执行跟踪后的模型
</span><span class="n">result</span> <span class="o">=</span> <span class="nf">traced_f</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</code></pre></div></div> <p><strong>优点：</strong></p> <ul> <li>✓ 易于实现</li> <li>✓ 易于调试</li> <li>✓ 与动态图执行方式相同</li> </ul> <p><strong>缺点：</strong></p> <ul> <li>✗ 只记录一次执行的路径</li> <li>✗ 难以支持条件分支</li> <li>✗ 难以处理依赖输入形状的操作</li> </ul> <p><strong>局限性示例：</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">conditional_func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># 问题：跟踪只记录一个分支
</span><span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">trace</span><span class="p">(</span><span class="n">conditional_func</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="c1"># 用其他输入执行时可能走另一个分支，但图里只有记录的分支
</span></code></pre></div></div> <h3 id="方法-2-源码转换法ast-based-source-transformation">方法 2: 源码转换法（AST-Based Source Transformation）</h3> <p><strong>原理：</strong> 解析 Python 源代码，转换为中间表示（IR）</p> <p><strong>过程：</strong></p> <ol> <li>解析（Parse）：得到抽象语法树（AST）</li> <li>推断（Infer）：完成类型推断和代码规范化</li> <li>转换（Transform）：将 AST 转换为计算图 IR</li> <li>优化（Optimize）：对 IR 进行优化</li> <li>编译（Compile）：生成本地代码</li> </ol> <p><strong>代表实现：</strong></p> <ul> <li> <code class="language-plaintext highlighter-rouge">@torch.jit.script</code>：JIT 脚本编译</li> <li> <code class="language-plaintext highlighter-rouge">torch.compile()</code>：TorchDynamo + 后端编译器</li> <li> <code class="language-plaintext highlighter-rouge">@tf.function</code>：TensorFlow 函数追踪</li> </ul> <p><strong>示例：</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 方式1: JIT script（源码级转换）
</span><span class="nd">@torch.jit.script</span>
<span class="k">def</span> <span class="nf">conditional_func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># 方式2: torch.compile（动态优化）
</span><span class="nd">@torch.compile</span>
<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="nf">return </span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">).</span><span class="nf">relu</span><span class="p">()</span> <span class="o">*</span> <span class="mi">2</span>
</code></pre></div></div> <p><strong>优点：</strong></p> <ul> <li>✓ 支持更广泛的控制流</li> <li>✓ 支持高阶梯度计算</li> <li>✓ 生成的图更完整</li> </ul> <p><strong>缺点：</strong></p> <ul> <li>✗ 实现复杂度高</li> <li>✗ 生成的代码难以理解</li> <li>✗ 需要强大的错误检查系统</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> {% include figure.liquid loading="eager" path="assets/img/notes_img/AIP-ch10/graph_capture_comparison.png" title="图捕获方法对比" class="img-fluid rounded z-depth-1" zoomable=true %} </div> </div> <h3 id="pytorch-20-的混合方案">PyTorch 2.0 的混合方案</h3> <p>PyTorch 2.0 通过 <code class="language-plaintext highlighter-rouge">torch.compile()</code> 结合两种方法：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>

<span class="c1"># 用户代码保持完全动态
</span><span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nf">return </span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">).</span><span class="nf">relu</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nf">return </span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">).</span><span class="nf">relu</span><span class="p">()</span>

<span class="c1"># 编译器自动优化
</span><span class="n">compiled_model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># 第一次调用：捕获图
</span><span class="n">result1</span> <span class="o">=</span> <span class="nf">compiled_model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

<span class="c1"># 后续调用：使用优化的静态图
</span><span class="n">result2</span> <span class="o">=</span> <span class="nf">compiled_model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</code></pre></div></div> <p><strong>执行过程：</strong></p> <ol> <li>TorchDynamo 截获 Python 字节码</li> <li>识别可编译的子图</li> <li>对每个子图生成 IR</li> <li>后端编译器优化 IR</li> <li>执行编译后的代码</li> </ol> <h2 id="ai-框架的三代发展">AI 框架的三代发展</h2> <p>深度学习框架的演进经历了三个阶段，每个阶段都在编程灵活性和执行效率之间找到不同的平衡点。</p> <h3 id="第一代库基础library-based-pre-2010">第一代：库基础（Library-Based, pre-2010）</h3> <p><strong>代表框架：</strong> NumPy、SciPy、MATLAB</p> <p><strong>特点：</strong></p> <ul> <li>提供基础数学库函数</li> <li>用户手动组合库函数实现算法</li> <li>基于表达式的自动微分实现</li> </ul> <p><strong>优点：</strong></p> <ul> <li>实现简单</li> <li>通用性强</li> </ul> <p><strong>缺点：</strong></p> <ul> <li>编程复杂，需要大量库函数调用</li> <li>无法使用高级语言的原生语法</li> <li>新操作需要手动微分</li> </ul> <h3 id="第二代dag-基础dag-based-2010-present">第二代：DAG 基础（DAG-Based, 2010-present）</h3> <p><strong>代表框架：</strong> TensorFlow 1.x、Caffe、Theano</p> <p><strong>特点：</strong></p> <ul> <li>使用有向无环图表示计算</li> <li>明确的操作符（节点）和张量（边）</li> <li>支持对计算图的全局优化</li> </ul> <p><strong>分为两个方向：</strong></p> <p><strong>方向 A：性能优先</strong> - TensorFlow</p> <ul> <li>静态图，编译优化能力强</li> <li>执行效率高，但灵活性受限</li> </ul> <p><strong>方向 B：灵活性优先</strong> - PyTorch</p> <ul> <li>动态图，支持即时开发</li> <li>编程简单，但优化能力有限</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> {% include figure.liquid loading="eager" path="assets/img/notes_img/AIP-ch10/three_generations.png" title="AI 框架的三代发展" class="img-fluid rounded z-depth-1" zoomable=true %} </div> </div> <h3 id="第三代源码转换法ast-basedpresent">第三代：源码转换法（AST-Based，Present）</h3> <p><strong>代表框架：</strong> PyTorch 2.0、TensorFlow 2.0、JAX、MindSpore</p> <p><strong>特点：</strong></p> <ul> <li>结合命令式编程的易用性和函数式编程的优化方式</li> <li>动态图编程 + 静态子图优化</li> <li>灵活性和效率的完美融合</li> </ul> <p><strong>关键创新：</strong></p> <ol> <li> <p><strong>全局动态</strong> → <strong>局部静态</strong></p> <ul> <li>程序整体采用动态图，用户可自由使用 Python 特性</li> <li>在特定函数/模块处理为静态子图进行优化</li> </ul> </li> <li> <p><strong>自动图捕获</strong></p> <ul> <li>框架自动捕获特定函数的执行</li> <li>转换为可优化的静态图</li> </ul> </li> <li> <p><strong>智能优化</strong></p> <ul> <li>代码优化（死代码消除、公共子表达式）</li> <li>稀疏性优化</li> <li>硬件感知优化</li> </ul> </li> </ol> <p><strong>代表技术：</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PyTorch 2.0
</span><span class="nd">@torch.compile</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 自动优化为静态子图
</span>
<span class="c1"># JAX
</span><span class="n">jitted_fn</span> <span class="o">=</span> <span class="n">jax</span><span class="p">.</span><span class="nf">jit</span><span class="p">(</span><span class="n">forward</span><span class="p">)</span>

<span class="c1"># TensorFlow 2.0
</span><span class="nd">@tf.function</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <h2 id="计算图的优化与执行">计算图的优化与执行</h2> <h3 id="图优化graph-optimization">图优化（Graph Optimization）</h3> <p>计算图被构建后，在执行前进行多种优化：</p> <ol> <li> <p><strong>算子融合（Operator Fusion）</strong></p> <ul> <li>将多个小算子合并为一个大算子</li> <li>减少内存访问和数据传输</li> </ul> </li> <li> <p><strong>批处理（Batching）</strong></p> <ul> <li>将多个独立计算合并为批处理</li> <li>提高硬件利用率</li> </ul> </li> <li> <p><strong>缓存优化（Cache Optimization）</strong></p> <ul> <li>优化数据访问模式</li> <li>提高 CPU 缓存命中率</li> </ul> </li> <li> <p><strong>内存管理（Memory Management）</strong></p> <ul> <li>合理分配和释放中间张量内存</li> <li>支持梯度检查点节省显存</li> </ul> </li> </ol> <h3 id="图调度执行graph-dispatch--execution">图调度执行（Graph Dispatch &amp; Execution）</h3> <p>优化后的图被调度到不同的硬件执行：</p> <ul> <li> <strong>CPU 执行</strong>：多线程并行</li> <li> <strong>GPU 执行</strong>：使用 CUDA 核函数</li> <li> <strong>分布式执行</strong>：跨机器、跨 GPU 通信</li> </ul> <h2 id="总结">总结</h2> <p><strong>计算图</strong>是现代 AI 框架的核心抽象：</p> <ol> <li> <strong>统一表示</strong>：用 DAG 统一表示神经网络和梯度计算</li> <li> <strong>支持多种操作</strong>：张量操作、网络操作、控制流操作</li> <li> <strong>支持多种张量</strong>：密集、不规则、稀疏张量</li> <li> <strong>灵活性与效率的融合</strong> <ul> <li>全局：动态图编程的灵活性</li> <li>局部：静态子图的执行效率</li> </ul> </li> <li> <strong>自动优化</strong>：框架自动对图进行优化和并行化</li> </ol> <p>现代 AI 框架（PyTorch、TensorFlow、JAX）都在朝着这个方向演进，为用户提供既灵活又高效的深度学习开发体验。</p> <p><strong>下一步：</strong> 图优化、自动求导实现、分布式执行等具体技术细节。</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesof_ML/">notes of ML</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesofvci/">notes of VCI</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesofaip/">notes of AIP</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesof_aimath/">notes of AI Math Fundamentals</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/09/08/notesof_ICS/">notes of ICS</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 stibiums liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: October 30, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?58fdb075e5aa03fbb8617845abde746c"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>